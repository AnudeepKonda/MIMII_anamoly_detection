{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bff1e8a",
   "metadata": {},
   "source": [
    "# Dataset MIMII\n",
    "\n",
    "Read a good description of the dataset here:\n",
    "\n",
    "https://github.com/BA-HanseML/NF_Prj_MIMII_Dataset/blob/master/doc/about_the_dataset.md \n",
    "\n",
    "\n",
    "A showroom of the recordings is available here:\n",
    "https://ba-hanseml.github.io/MIMII_show_room/showroom.html\n",
    "\n",
    "https://github.com/BA-HanseML/NF_Prj_MIMII_Dataset/blob/master/NF_Prj_MIMII_presentation_short.pdf\n",
    "\n",
    "## Machine parts\n",
    "There are 4 machine parts and their audio recordings. Each machine part has a normal and abnormal recording.\n",
    "\n",
    "- pump\n",
    "- valve\n",
    "- rail slider\n",
    "- fan\n",
    "\n",
    "## Dataset Structure\n",
    "https://github.com/BA-HanseML/NF_Prj_MIMII_Dataset/blob/master/dataset/dataset_struct.md \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unknown-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import glob\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "import PIL as Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc97b7e",
   "metadata": {},
   "source": [
    "# General config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "streaming-lemon",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Please edit as needed. This is the path to pngs\n",
    "base_data_path = \"./data/wav_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9ed475",
   "metadata": {},
   "source": [
    "Anudeep some thoughts on the dataloader.\n",
    "- If we consider a supervised method. The dataloader should only read the normal data and store [spectrogram, label]. label can be [0, 1, 2, 3] (pump, valve, fan, slider )\n",
    "- If we consider a 1-class unsupervised method. We should train only on normal data of a particular class. ie\n",
    "class MIMII(Dataset):\n",
    "    def __init__(self, data_paths, machine).\n",
    "and the label can be [1, 0]. ie normal or abnormal \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "practical-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "from collections import defaultdict\n",
    "\n",
    "class MIMII(Dataset):\n",
    "    def __init__(self, base_path, machine):\n",
    "        \n",
    "        # Parameters for conversion to MEL spectrogram \n",
    "        self.n_mels = 64\n",
    "        self.frames = 5\n",
    "        self.n_fft = 2048\n",
    "        self.hop_length = 512\n",
    "        self.power = 2.0\n",
    "        self.base_path = base_path\n",
    "        assert type(machine) == list\n",
    "        assert len(machine) > 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "               \n",
    "            \n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # return and indexed item from the list\n",
    "        # NOTE: There are 8 spectrograms per audio, one for each microphone\n",
    "        return torch.from_numpy(self.spectrograms[index]), torch.from_numpy(np.array([self.labels[index]])),\\\n",
    "    torch.from_numpy(self.sampling_rates[index])\n",
    "    \n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        # number of samples loaded\n",
    "        return len(self.)\n",
    "    \n",
    "        \n",
    "    def convert_to_spectrogram(self, wav_file_path):\n",
    "        signal, sampling_rate = self.load_sound_file(wav_file_path)\n",
    "        \n",
    "#         ## Perform fourier transform\n",
    "#         stft = librosa.stft(signal, n_fft=self.n_fft, hop_length=self.hop_length)\n",
    "#         # Map the magnitude to a decibel scale:\n",
    "#         dB = librosa.amplitude_to_db(np.abs(stft), ref=np.max)\n",
    "        \n",
    "        ## Mel spectrogram calculation\n",
    "        images = []\n",
    "        for channel in range(signal.shape[0]):\n",
    "            mel = librosa.feature.melspectrogram(signal[channel], sr=sampling_rate, n_fft=self.n_fft, hop_length=self.hop_length,\\\n",
    "                                             n_mels=self.n_mels)\n",
    "            db_mel = librosa.power_to_db(mel, ref=np.max)\n",
    "            img = scale_minmax(db_mel, 0, 255).astype(np.uint8)\n",
    "            img = np.flip(img, axis=0)\n",
    "            img = 255 - img\n",
    "            img = Image.fromarray(img)\n",
    "            images.append(img)\n",
    "        \n",
    "        return np.array(images), np.array(sampling_rate)\n",
    "        \n",
    "    \n",
    "    def load_sound_file(self, wav_name, mono=False, channel=0):\n",
    "        multi_channel_data, sampling_rate = librosa.load(wav_name, sr=None, mono=mono)\n",
    "        signal = np.array(multi_channel_data)\n",
    "    \n",
    "        return signal, sampling_rate\n",
    "    \n",
    "    \n",
    "    def scale_minmax(self, X, _min=0.0, _max=1.0):\n",
    "        \"\"\"\n",
    "        Minmax scaler for a numpy array\n",
    "\n",
    "        PARAMS\n",
    "        ======\n",
    "            X (numpy array) - array to scale\n",
    "            min (float) - minimum value of the scaling range (default: 0.0)\n",
    "            max (float) - maximum value of the scaling range (default: 1.0)\n",
    "        \"\"\"\n",
    "        X_std = (X - X.min()) / (X.max() - X.min())\n",
    "        X_scaled = X_std * (_max - _min) + _min\n",
    "        \n",
    "        return X_scaled\n",
    "    \n",
    "    transform = T.Compose([T.ToPILImage(), T.ToTensor()])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bearing-buying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_map: {'fan': 0, 'pump': 1, 'slider': 2, 'valve': 3}\n"
     ]
    }
   ],
   "source": [
    "dataset = MIMII(base_data_path, snr=\"6_dB\", machine=['fan', 'pump', 'slider', 'valve'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "extensive-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size=10, shuffle=True, num_workers=2)\n",
    "iterable = iter(dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_machine",
   "language": "python",
   "name": "pytorch_machine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
