{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unknown-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "oriented-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/ubuntu/anudeep/machine_sound/\"\n",
    "paths = glob.glob(data_path+\"0_dB_fan/*/*/*/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "streaming-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "class MIMII(Dataset):\n",
    "    def __init__(self, data_paths):\n",
    "        self.n_mels = 64\n",
    "        self.frames = 5\n",
    "        self.n_fft = 2048\n",
    "        self.hop_length = 512\n",
    "        self.power = 2.0\n",
    "        \n",
    "        # convert audio to spectograms\n",
    "        \n",
    "        self.spectrograms = []\n",
    "        self.labels = []\n",
    "        \n",
    "        t = trange(len(data_paths), desc='Converting audio files to spectrograms', leave=True)        \n",
    "        for index in t:\n",
    "            t.set_description(\"Converting file no. %i of %i\" % (index, len(data_paths)))\n",
    "            t.refresh()\n",
    "            \n",
    "            wav_file_path = data_paths[index]\n",
    "            if \"abnormal\" in wav_file_path:\n",
    "                curr_label = 1\n",
    "            elif \"normal\" in wav_file_path:\n",
    "                curr_label = 0\n",
    "            else:\n",
    "                curr_label = -1\n",
    "            \n",
    "            curr_spectrogram = self.convert_to_spectrogram(wav_file_path)\n",
    "            self.spectrograms.append(curr_spectrogram)\n",
    "            self.labels.append(curr_label)\n",
    "            \n",
    "            \n",
    "    def __get_item__(self, index):\n",
    "        \n",
    "        # return and indexed item from the list\n",
    "        return self.transform(self.spectrograms[index]), self.transform(self.labels[index])\n",
    "    \n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        # number of samples loaded\n",
    "        return len(self.data_paths)\n",
    "    \n",
    "        \n",
    "    def convert_to_spectrogram(self, wav_file_path):\n",
    "        signal, sampling_rate = self.load_sound_file(wav_file_path)\n",
    "        \n",
    "#         ## Perform fourier transform\n",
    "#         stft = librosa.stft(signal, n_fft=self.n_fft, hop_length=self.hop_length)\n",
    "#         # Map the magnitude to a decibel scale:\n",
    "#         dB = librosa.amplitude_to_db(np.abs(stft), ref=np.max)\n",
    "        \n",
    "        ## Mel spectrogram calculation\n",
    "        db_mels = []\n",
    "        for channel in range(signal.shape[0]):\n",
    "            mel = librosa.feature.melspectrogram(signal[channel], sr=sampling_rate, n_fft=self.n_fft, hop_length=self.hop_length,\\\n",
    "                                             n_mels=self.n_mels)\n",
    "            db_mel = librosa.power_to_db(mel, ref=np.max)\n",
    "            db_mels.append(db_mel)\n",
    "        \n",
    "        return np.array(db_mels)\n",
    "        \n",
    "    \n",
    "    def load_sound_file(self, wav_name, mono=False, channel=0):\n",
    "        multi_channel_data, sampling_rate = librosa.load(wav_name, sr=None, mono=mono)\n",
    "        signal = np.array(multi_channel_data)\n",
    "    \n",
    "        return signal, sampling_rate\n",
    "    \n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-tackle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting file no. 714 of 5550:  13%|█▎        | 715/5550 [02:26<21:07,  3.81it/s]"
     ]
    }
   ],
   "source": [
    "a = MIMII(paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_machine",
   "language": "python",
   "name": "pytorch_machine"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
