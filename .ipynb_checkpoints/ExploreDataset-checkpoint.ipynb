{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bff1e8a",
   "metadata": {},
   "source": [
    "# Dataset MIMII\n",
    "\n",
    "Read a good description of the dataset here:\n",
    "\n",
    "https://github.com/BA-HanseML/NF_Prj_MIMII_Dataset/blob/master/doc/about_the_dataset.md \n",
    "\n",
    "\n",
    "A showroom of the recordings is available here:\n",
    "https://ba-hanseml.github.io/MIMII_show_room/showroom.html\n",
    "\n",
    "https://github.com/BA-HanseML/NF_Prj_MIMII_Dataset/blob/master/NF_Prj_MIMII_presentation_short.pdf\n",
    "\n",
    "## Machine parts\n",
    "There are 4 machine parts and their audio recordings. Each machine part has a normal and abnormal recording.\n",
    "\n",
    "- pump\n",
    "- valve\n",
    "- rail slider\n",
    "- fan\n",
    "\n",
    "## Dataset Structure\n",
    "https://github.com/BA-HanseML/NF_Prj_MIMII_Dataset/blob/master/dataset/dataset_struct.md \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unknown-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import glob\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "import PIL as Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc97b7e",
   "metadata": {},
   "source": [
    "# General config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "streaming-lemon",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Please edit as needed. This is the path to pngs\n",
    "base_data_path = \"./dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9ed475",
   "metadata": {},
   "source": [
    "Anudeep some thoughts on the dataloader.\n",
    "- If we consider a supervised method. The dataloader should only read the normal data and store [spectrogram, label]. label can be [0, 1, 2, 3] (pump, valve, fan, slider )\n",
    "- If we consider a 1-class unsupervised method. We should train only on normal data of a particular class. ie\n",
    "class MIMII(Dataset):\n",
    "    def __init__(self, data_paths, machine).\n",
    "and the label can be [1, 0]. ie normal or abnormal \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "practical-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "from collections import defaultdict\n",
    "\n",
    "class MIMII(Dataset):\n",
    "    def __init__(self, base_path, snr, machine):\n",
    "        \n",
    "        # Parameters for conversion to MEL spectrogram \n",
    "        self.n_mels = 64\n",
    "        self.frames = 5\n",
    "        self.n_fft = 2048\n",
    "        self.hop_length = 512\n",
    "        self.power = 2.0\n",
    "        self.base_path = base_path\n",
    "        assert type(machine) == list\n",
    "        assert len(machine) > 1\n",
    "        \n",
    "        # group paths by unique audio file\n",
    "        self.normal_paths = glob.glob(base_path + \"normal/{}*.png\".format(snr))\n",
    "        self.normal_paths.sort()\n",
    "        self.abnormal_paths = glob.glob(base_path + \"abnormal/{}*.png\".format(snr))\n",
    "        self.abnormal_paths.sort()\n",
    "        self.normal_file_count = len(self.normal_paths) / 8\n",
    "        self.abnormal_file_count = len(self.abnormal_paths) / 8\n",
    "        self.normal_files = defaultdict(list)\n",
    "        self.abnormal_files = defaultdict(list)\n",
    "        \n",
    "        for f in self.normal_paths:\n",
    "            file_name = f.split(\"/\")[-1][:-8]\n",
    "            \n",
    "            if file_name in self.normal_files.keys():\n",
    "                self.normal_files[file_name].append(f)\n",
    "            \n",
    "            else:\n",
    "                self.normal_files[file_name] = [f]\n",
    "        \n",
    "        # NOTE: We aren't using abnormal files in the current setting. This is to support future experiments\n",
    "        for f in self.abnormal_paths:\n",
    "            file_name = f.split(\"/\")[-1][:-8]\n",
    "            \n",
    "            if file_name in self.abnormal_files.keys():\n",
    "                self.abnormal_files[file_name].append(f)\n",
    "            \n",
    "            else:\n",
    "                self.abnormal_files[file_name] = [f]\n",
    "        \n",
    "        self.label_map = {s:ctr for ctr, s in enumerate(machine)}\n",
    "        print(\"label_map: {}\".format(self.label_map))          \n",
    "            \n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # return and indexed item from the list\n",
    "        # NOTE: There are 8 spectrograms per audio, one for each microphone\n",
    "        key = list(self.normal_files.keys())[index]\n",
    "        img_file_list = self.normal_files[key]\n",
    "        images = []\n",
    "        \n",
    "        for f in img_file_list:\n",
    "            img = np.asarray(Image.Image.open(f))\n",
    "            images.append(img)\n",
    "            \n",
    "        _machine = key.split('-')[0].split('_')[-1]\n",
    "        label = self.label_map[_machine]\n",
    "        \n",
    "        return torch.from_numpy(np.array(images)), torch.from_numpy(np.array([label]))\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        # number of samples loaded\n",
    "        return int(self.normal_file_count)\n",
    "    \n",
    "        \n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bearing-buying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_map: {'fan': 0, 'pump': 1, 'slider': 2, 'valve': 3}\n"
     ]
    }
   ],
   "source": [
    "dataset = MIMII(base_data_path, snr=\"6_dB\",machine=['fan', 'pump', 'slider', 'valve'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "extensive-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size=10, shuffle=True, num_workers=2)\n",
    "iterable = iter(dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_machine",
   "language": "python",
   "name": "pytorch_machine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
